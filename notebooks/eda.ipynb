{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7d5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb69b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and combined 11 AFDC files into a single DF.\n",
      "Total records: 16721\n",
      "Years found: [np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "Combined AFDC data saved to ../data/processed/combined_afdc_data.csv\n",
      "Loaded 676 charging stations.\n",
      "Loaded 47785 road segments.\n",
      "Loaded 29895 shops.\n",
      "Loaded 53416 leisure spots.\n",
      "Loaded 125104 residential buildings.\n",
      "Loaded 145434 amenities.\n"
     ]
    }
   ],
   "source": [
    "'''Step 1:\n",
    "  Conacanate AFDC historical data files into a single DataFrame.\n",
    "    Load cleaned geojson files into GeoDataFrames.\n",
    "'''\n",
    "#Loading cleaned data\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "processed_path = \"../data/processed/\"\n",
    "afdc_files = glob.glob(os.path.join(processed_path, \"alt_fuel_stations_historical_day*.csv\"))\n",
    "\n",
    "if not afdc_files:\n",
    "    raise FileNotFoundError(\"No AFDC historical data files found in the processed data directory.\")\n",
    "\n",
    "#Create a list to hold each year's DataFrame\n",
    "else:\n",
    "    afdc_df_list = []\n",
    "    for file in afdc_files:\n",
    "        try:\n",
    "            year = int(file.split('(')[-1].split(')')[0].split(' ')[-1])\n",
    "            temp_df = pd.read_csv(file)\n",
    "            temp_df['Year'] = year\n",
    "            afdc_df_list.append(temp_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "#Combine all years into single DataFrame\n",
    "if afdc_df_list:\n",
    "    afdc_data = pd.concat(afdc_df_list, ignore_index=True)\n",
    "    print(f\"Successfully loaded and combined {len(afdc_files)} AFDC files into a single DF.\")\n",
    "    print(f\"Total records: {len(afdc_data)}\")\n",
    "    print(f\"Years found: {sorted(afdc_data['Year'].unique())}\")\n",
    "else:\n",
    "    \n",
    "    print(\"Warning: No data was loaded into the afdc_df_list.\")\n",
    "    afdc_data = pd.DataFrame()\n",
    "\n",
    "#Saving loaded data to a single file for easier access in future steps\n",
    "combined_afdc_path = \"../data/processed/combined_afdc_data.csv\" \n",
    "try:\n",
    "    afdc_data.to_csv(combined_afdc_path, index=False)\n",
    "    print(f\"Combined AFDC data saved to {combined_afdc_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving combined AFDC data: {e}\")\n",
    "\n",
    "#Load geojson data\n",
    "try:\n",
    "    gdf_chargers = gpd.read_file(os.path.join(processed_path, \"chargingStationWashington_cleaned.geojson\"))\n",
    "    gdf_roads = gpd.read_file(os.path.join(processed_path, \"majorRoadsWashington_cleaned.geojson\"))\n",
    "    gdf_shops = gpd.read_file(os.path.join(processed_path, \"shopsWashington_cleaned.geojson\"))\n",
    "    gdf_leisure = gpd.read_file(os.path.join(processed_path, \"leisureWashington_cleaned.geojson\"))\n",
    "    gdf_residential = gpd.read_file(os.path.join(processed_path, \"residentialWashington_cleaned.geojson\"))\n",
    "    gdf_amenities = gpd.read_file(os.path.join(processed_path, \"amenitiesWashington_cleaned.geojson\"))\n",
    "\n",
    "\n",
    "    print(f\"Loaded {len(gdf_chargers)} charging stations.\")\n",
    "    print(f\"Loaded {len(gdf_roads)} road segments.\")\n",
    "    print(f\"Loaded {len(gdf_shops)} shops.\")\n",
    "    print(f\"Loaded {len(gdf_leisure)} leisure spots.\")\n",
    "    print(f\"Loaded {len(gdf_residential)} residential buildings.\")\n",
    "    print(f\"Loaded {len(gdf_amenities)} amenities.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}. Make sure all cleaned files are in the 'processed' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b960eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined all POIs into a single dataframe with 353849 records.\n",
      "All GeoDataFrames reprojected to EPSG:32148.\n"
     ]
    }
   ],
   "source": [
    "poi_list = [gdf_shops, gdf_leisure, gdf_residential, gdf_amenities]\n",
    "gdf_pois = pd.concat(poi_list, ignore_index=True)\n",
    "print(f\"Combined all POIs into a single dataframe with {len(gdf_pois)} records.\")\n",
    "\n",
    "#Set CRS (coordinate reference system) to ESPG:32148, Washington's (NAD83) projected CRS\n",
    "target_crs = \"EPSG:32148\"\n",
    "gdf_chargers = gdf_chargers.to_crs(target_crs)\n",
    "gdf_roads = gdf_roads.to_crs(target_crs)\n",
    "gdf_pois = gdf_pois.to_crs(target_crs)\n",
    "\n",
    "print(\"All GeoDataFrames reprojected to EPSG:32148.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851d3cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdf_shops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# --- Step 1: Combine all POI GeoDataFrames into one ---\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# This makes it much easier to calculate the density for all POI types at once.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m poi_list = [\u001b[43mgdf_shops\u001b[49m, gdf_leisure, gdf_residential, gdf_amenities] \u001b[38;5;66;03m# gdf_amenities is now included\u001b[39;00m\n\u001b[32m     12\u001b[39m gdf_pois = pd.concat(poi_list, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- POI Combination Complete ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'gdf_shops' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculating proximity and density metrics, using TQDM, cool side node\n",
    "tqdm's name derives from the Arabic word taqadum which means progress because\n",
    "tqdm is a fast, extensible progress bar for Python and CLI.\"\"\"\n",
    "from tqdm.notebook import tqdm\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Combine all POI GeoDataFrames into one ---\n",
    "# This makes it much easier to calculate the density for all POI types at once.\n",
    "# This step fixes the \"gdf_pois is not defined\" error.\n",
    "poi_list = [gdf_shops, gdf_leisure, gdf_residential, gdf_amenities]\n",
    "gdf_pois = pd.concat(poi_list, ignore_index=True)\n",
    "\n",
    "print(f\"--- POI Combination Complete ---\")\n",
    "print(f\"Combined all POIs into a single GeoDataFrame with {len(gdf_pois)} features.\")\n",
    "\n",
    "\n",
    "# --- Step 2: Re-project all GeoDataFrames to a Projected CRS ---\n",
    "# This step fixes the UserWarning and ensures your distance calculations are accurate (in meters).\n",
    "target_crs = \"EPSG:32148\" # A good projected CRS for Washington\n",
    "\n",
    "print(f\"\\n--- Re-projecting all GeoDataFrames to {target_crs} for accurate calculations ---\")\n",
    "gdf_chargers = gdf_chargers.to_crs(target_crs)\n",
    "gdf_roads = gdf_roads.to_crs(target_crs)\n",
    "gdf_pois = gdf_pois.to_crs(target_crs)\n",
    "print(\"Re-projection complete.\")\n",
    "\n",
    "\n",
    "# --- Step 3: Calculate Proximity and Density Metrics ---\n",
    "tqdm.pandas(desc=\"Calculating distances\")  # Enable tqdm for pandas\n",
    "\n",
    "major_road_types = ['motorway', 'trunk', 'primary', 'secondary']\n",
    "gdf_major_roads = gdf_roads[gdf_roads['highway'].isin(major_road_types)]\n",
    "print(f\"\\nFiltered roads down to {len(gdf_major_roads)} major road segments.\")\n",
    "\n",
    "print(\"\\nCalculating distance to nearest major road...\")\n",
    "\"\"\"\n",
    "Code below works like this. Firstly, we add a new column 'dist_to_major_road_m' to gdf_chargers.\n",
    "then we select the geometry key from the gdf_chargers GeoDataFrame, which contains the point geometries of the charging stations.\n",
    "the line progress apply tells pandas to apply a defined function to each point in the geometry column, while also displaying a progress bar using tqdm.\n",
    "lambda point is like an anonymous mini-function that you dont make a funtion for. Then it calculates the distance from point(the charging station)\n",
    "to all geometries in gdf_major_roads using gdf_major_roads.distance(point). min function is there since the function finds distances to all roads\n",
    "in the dataset and we only want the minimum distance, which is the nearest road.\n",
    "\n",
    "\"\"\"\n",
    "gdf_chargers['dist_to_major_road_m'] = gdf_chargers.geometry.progress_apply(\n",
    "    lambda point: gdf_major_roads.distance(point).min()\n",
    ")\n",
    "print(\"Distance calculation complete.\")\n",
    "\n",
    "print(\"\\nCalculating POI density within 500 meters...\")\n",
    "# Step 1: Create a 500-meter circular buffer around each charging station\n",
    "buffers = gdf_chargers.geometry.buffer(500)\n",
    "\n",
    "# Step 2: Perform a spatial join to find all POIs that fall within each buffer\n",
    "\"\"\"\n",
    " Explanation of spatial join:\n",
    " the left gdf is gdf_pois, which contains the point geometries of the POIs. then the right\n",
    " gdf is each charging station with the 500m buffer around it. The join is an inner join\n",
    " meaning that POIs thast fall within the 500m buffer of any charging station will be kept in the result.\n",
    " The predicate \"within\" specifies that we are looking for POIs that are located within the buffer areas.\n",
    " \n",
    "\"\"\"\n",
    "joined_pois = gpd.sjoin(gdf_pois, gpd.GeoDataFrame(geometry=buffers), how=\"inner\", predicate=\"within\")\n",
    "\n",
    "# Step 3: Group by the charging station's index and count the number of POIs\n",
    "poi_counts = joined_pois.groupby(joined_pois.index).size()\n",
    "\n",
    "# Step 4: Add the counts to your main DataFrame and fill empty values with 0\n",
    "gdf_chargers['poi_density_500m'] = poi_counts\n",
    "gdf_chargers['poi_density_500m'] = gdf_chargers['poi_density_500m'].fillna(0)\n",
    "print(\"POI density calculation complete.\")\n",
    "\n",
    "\n",
    "# --- Step 4: Display and Save Results ---\n",
    "print(\"\\n--- Feature Engineering Complete ---\")\n",
    "print(\"first 5 rows of gdf_chargers with new features:\")\n",
    "print(gdf_chargers[['dist_to_major_road_m', 'poi_density_500m']].head())\n",
    "\n",
    "print(\"\\nSaving updated GeoDataFrame...\")\n",
    "output_path = \"../data/processed/stations_with_features.geojson\"\n",
    "try:\n",
    "    gdf_chargers.to_file(output_path, driver='GeoJSON')\n",
    "    print(f\"Updated GeoDataFrame saved to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving updated GeoDataFrame: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
