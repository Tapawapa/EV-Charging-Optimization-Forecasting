{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7d5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb69b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and combined 11 AFDC files into a single DF.\n",
      "Total records: 16721\n",
      "Years found: [np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "Combined AFDC data saved to ../data/processed/combined_afdc_data.csv\n",
      "Loaded 676 charging stations.\n",
      "Loaded 47785 road segments.\n",
      "Loaded 29895 shops.\n",
      "Loaded 53416 leisure spots.\n",
      "Loaded 125104 residential buildings.\n",
      "Loaded 145434 amenities.\n"
     ]
    }
   ],
   "source": [
    "'''Step 1:\n",
    "  Conacanate AFDC historical data files into a single DataFrame.\n",
    "    Load cleaned geojson files into GeoDataFrames.\n",
    "'''\n",
    "#Loading cleaned data\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "processed_path = \"../data/processed/\"\n",
    "afdc_files = glob.glob(os.path.join(processed_path, \"alt_fuel_stations_historical_day*.csv\"))\n",
    "\n",
    "if not afdc_files:\n",
    "    raise FileNotFoundError(\"No AFDC historical data files found in the processed data directory.\")\n",
    "\n",
    "#Create a list to hold each year's DataFrame\n",
    "else:\n",
    "    afdc_df_list = []\n",
    "    for file in afdc_files:\n",
    "        try:\n",
    "            year = int(file.split('(')[-1].split(')')[0].split(' ')[-1])\n",
    "            temp_df = pd.read_csv(file)\n",
    "            temp_df['Year'] = year\n",
    "            afdc_df_list.append(temp_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "#Combine all years into single DataFrame\n",
    "if afdc_df_list:\n",
    "    afdc_data = pd.concat(afdc_df_list, ignore_index=True)\n",
    "    print(f\"Successfully loaded and combined {len(afdc_files)} AFDC files into a single DF.\")\n",
    "    print(f\"Total records: {len(afdc_data)}\")\n",
    "    print(f\"Years found: {sorted(afdc_data['Year'].unique())}\")\n",
    "else:\n",
    "    \n",
    "    print(\"Warning: No data was loaded into the afdc_df_list.\")\n",
    "    afdc_data = pd.DataFrame()\n",
    "\n",
    "#Saving loaded data to a single file for easier access in future steps\n",
    "combined_afdc_path = \"../data/processed/combined_afdc_data.csv\" \n",
    "try:\n",
    "    afdc_data.to_csv(combined_afdc_path, index=False)\n",
    "    print(f\"Combined AFDC data saved to {combined_afdc_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving combined AFDC data: {e}\")\n",
    "\n",
    "#Load geojson data\n",
    "try:\n",
    "    gdf_chargers = gpd.read_file(os.path.join(processed_path, \"chargingStationWashington_cleaned.geojson\"))\n",
    "    gdf_roads = gpd.read_file(os.path.join(processed_path, \"majorRoadsWashington_cleaned.geojson\"))\n",
    "    gdf_shops = gpd.read_file(os.path.join(processed_path, \"shopsWashington_cleaned.geojson\"))\n",
    "    gdf_leisure = gpd.read_file(os.path.join(processed_path, \"leisureWashington_cleaned.geojson\"))\n",
    "    gdf_residential = gpd.read_file(os.path.join(processed_path, \"residentialWashington_cleaned.geojson\"))\n",
    "    gdf_amenities = gpd.read_file(os.path.join(processed_path, \"amenitiesWashington_cleaned.geojson\"))\n",
    "\n",
    "\n",
    "    print(f\"Loaded {len(gdf_chargers)} charging stations.\")\n",
    "    print(f\"Loaded {len(gdf_roads)} road segments.\")\n",
    "    print(f\"Loaded {len(gdf_shops)} shops.\")\n",
    "    print(f\"Loaded {len(gdf_leisure)} leisure spots.\")\n",
    "    print(f\"Loaded {len(gdf_residential)} residential buildings.\")\n",
    "    print(f\"Loaded {len(gdf_amenities)} amenities.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}. Make sure all cleaned files are in the 'processed' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b960eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined all POIs into a single dataframe with 353849 records.\n",
      "All GeoDataFrames reprojected to EPSG:32148.\n"
     ]
    }
   ],
   "source": [
    "poi_list = [gdf_shops, gdf_leisure, gdf_residential, gdf_amenities]\n",
    "gdf_pois = pd.concat(poi_list, ignore_index=True)\n",
    "print(f\"Combined all POIs into a single dataframe with {len(gdf_pois)} records.\")\n",
    "\n",
    "#Set CRS (coordinate reference system) to ESPG:32148, Washington's (NAD83) projected CRS\n",
    "target_crs = \"EPSG:32148\"\n",
    "gdf_chargers = gdf_chargers.to_crs(target_crs)\n",
    "gdf_roads = gdf_roads.to_crs(target_crs)\n",
    "gdf_pois = gdf_pois.to_crs(target_crs)\n",
    "\n",
    "print(\"All GeoDataFrames reprojected to EPSG:32148.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7851d3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- POI Combination Complete ---\n",
      "Combined all POIs into a single GeoDataFrame with 353849 features.\n",
      "\n",
      "--- Re-projecting all GeoDataFrames to EPSG:32148 for accurate calculations ---\n",
      "Re-projection complete.\n",
      "\n",
      "Filtered roads down to 47785 major road segments.\n",
      "\n",
      "Calculating distance to nearest major road...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbd43158328466ba8ee2bc4c69b0da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating distances:   0%|          | 0/676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance calculation complete.\n",
      "\n",
      "Calculating POI density within 500 meters...\n",
      "POI density calculation complete.\n",
      "\n",
      "--- Feature Engineering Complete ---\n",
      "first 5 rows of gdf_chargers with new features:\n",
      "   dist_to_major_road_m  poi_density_500m\n",
      "0             32.676352               2.0\n",
      "1           1887.571780               3.0\n",
      "2            156.935476               0.0\n",
      "3             74.914555               1.0\n",
      "4            374.378686               0.0\n",
      "\n",
      "Saving updated GeoDataFrame...\n",
      "Updated GeoDataFrame saved to ../data/processed/stations_with_features.geojson\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculating proximity and density metrics, using TQDM, cool side node\n",
    "tqdm's name derives from the Arabic word taqadum which means progress because\n",
    "tqdm is a fast, extensible progress bar for Python and CLI.\"\"\"\n",
    "from tqdm.notebook import tqdm\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Combine all POI GeoDataFrames into one ---\n",
    "# This makes it much easier to calculate the density for all POI types at once.\n",
    "# This step fixes the \"gdf_pois is not defined\" error.\n",
    "poi_list = [gdf_shops, gdf_leisure, gdf_residential, gdf_amenities]\n",
    "gdf_pois = pd.concat(poi_list, ignore_index=True)\n",
    "\n",
    "print(f\"--- POI Combination Complete ---\")\n",
    "print(f\"Combined all POIs into a single GeoDataFrame with {len(gdf_pois)} features.\")\n",
    "\n",
    "\n",
    "# --- Step 2: Re-project all GeoDataFrames to a Projected CRS ---\n",
    "# This step fixes the UserWarning and ensures your distance calculations are accurate (in meters).\n",
    "target_crs = \"EPSG:32148\" # A good projected CRS for Washington\n",
    "\n",
    "print(f\"\\n--- Re-projecting all GeoDataFrames to {target_crs} for accurate calculations ---\")\n",
    "gdf_chargers = gdf_chargers.to_crs(target_crs)\n",
    "gdf_roads = gdf_roads.to_crs(target_crs)\n",
    "gdf_pois = gdf_pois.to_crs(target_crs)\n",
    "print(\"Re-projection complete.\")\n",
    "\n",
    "\n",
    "# --- Step 3: Calculate Proximity and Density Metrics ---\n",
    "tqdm.pandas(desc=\"Calculating distances\")  # Enable tqdm for pandas\n",
    "\n",
    "major_road_types = ['motorway', 'trunk', 'primary', 'secondary']\n",
    "gdf_major_roads = gdf_roads[gdf_roads['highway'].isin(major_road_types)]\n",
    "print(f\"\\nFiltered roads down to {len(gdf_major_roads)} major road segments.\")\n",
    "\n",
    "print(\"\\nCalculating distance to nearest major road...\")\n",
    "\"\"\"\n",
    "Code below works like this. Firstly, we add a new column 'dist_to_major_road_m' to gdf_chargers.\n",
    "then we select the geometry key from the gdf_chargers GeoDataFrame, which contains the point geometries of the charging stations.\n",
    "the line progress apply tells pandas to apply a defined function to each point in the geometry column, while also displaying a progress bar using tqdm.\n",
    "lambda point is like an anonymous mini-function that you dont make a funtion for. Then it calculates the distance from point(the charging station)\n",
    "to all geometries in gdf_major_roads using gdf_major_roads.distance(point). min function is there since the function finds distances to all roads\n",
    "in the dataset and we only want the minimum distance, which is the nearest road.\n",
    "\n",
    "\"\"\"\n",
    "gdf_chargers['dist_to_major_road_m'] = gdf_chargers.geometry.progress_apply(\n",
    "    lambda point: gdf_major_roads.distance(point).min()\n",
    ")\n",
    "print(\"Distance calculation complete.\")\n",
    "\n",
    "print(\"\\nCalculating POI density within 500 meters...\")\n",
    "# Step 1: Create a 500-meter circular buffer around each charging station\n",
    "buffers = gdf_chargers.geometry.buffer(500)\n",
    "\n",
    "# Step 2: Perform a spatial join to find all POIs that fall within each buffer\n",
    "\"\"\"\n",
    " Explanation of spatial join:\n",
    " the left gdf is gdf_pois, which contains the point geometries of the POIs. then the right\n",
    " gdf is each charging station with the 500m buffer around it. The join is an inner join\n",
    " meaning that POIs thast fall within the 500m buffer of any charging station will be kept in the result.\n",
    " The predicate \"within\" specifies that we are looking for POIs that are located within the buffer areas.\n",
    " \n",
    "\"\"\"\n",
    "joined_pois = gpd.sjoin(gdf_pois, gpd.GeoDataFrame(geometry=buffers), how=\"inner\", predicate=\"within\")\n",
    "\n",
    "# Step 3: Group by the charging station's index and count the number of POIs\n",
    "poi_counts = joined_pois.groupby(joined_pois.index).size()\n",
    "\n",
    "# Step 4: Add the counts to your main DataFrame and fill empty values with 0\n",
    "gdf_chargers['poi_density_500m'] = poi_counts\n",
    "gdf_chargers['poi_density_500m'] = gdf_chargers['poi_density_500m'].fillna(0)\n",
    "print(\"POI density calculation complete.\")\n",
    "\n",
    "\n",
    "# --- Step 4: Display and Save Results ---\n",
    "print(\"\\n--- Feature Engineering Complete ---\")\n",
    "print(\"first 5 rows of gdf_chargers with new features:\")\n",
    "print(gdf_chargers[['dist_to_major_road_m', 'poi_density_500m']].head())\n",
    "\n",
    "print(\"\\nSaving updated GeoDataFrame...\")\n",
    "output_path = \"../data/processed/stations_with_features.geojson\"\n",
    "try:\n",
    "    gdf_chargers.to_file(output_path, driver='GeoJSON')\n",
    "    print(f\"Updated GeoDataFrame saved to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving updated GeoDataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc861d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4718 unique stations from the AFDC dataset.\n",
      "Combined 353849 points of interest.\n",
      "Re-projecting all data to EPSG:32148 for accurate meter-based calculations\n",
      "Re-projection complete.\n",
      "Calculating distance to nearest of 47785 major road segments...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3b8ec5b2b148ee96b5b011acc6fd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating road distances:   0%|          | 0/4718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance calculation complete.\n",
      "Calculating POI density within a 500-meter radius\n",
      "POI density calculation complete.\n",
      "\\n--- Feature Engineering Complete ---\n",
      "Sample of unique AFDC stations with new features:\n",
      "     ID Open Date  dist_to_major_road_m  poi_density_500m\n",
      "0   134       NaN            332.932701               8.0\n",
      "1  1160       NaN             61.177862               3.0\n",
      "2  1170       NaN             57.522281               0.0\n",
      "3  1200       NaN              2.257608               2.0\n",
      "4  1201       NaN            184.838663               0.0\n",
      "\\nSuccessfully saved updated GeoDataFrame to ../data/processed/afdc_unique_stations_with_features.geojson\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop duplicate station IDs to get unique stations, keeping the first entry\n",
    "afdc_unique = afdc_data.drop_duplicates(subset=['ID'], keep='first').copy()\n",
    "print(f\"Found {len(afdc_unique)} unique stations from the AFDC dataset.\")\n",
    "\n",
    "# Convert the unique AFDC DataFrame to a GeoDataFrame\n",
    "gdf_afdc_unique = gpd.GeoDataFrame(\n",
    "    afdc_unique,\n",
    "    geometry=gpd.points_from_xy(afdc_unique.Longitude, afdc_unique.Latitude),\n",
    "    crs=\"EPSG:4326\"  # Standard CRS for lat/lon\n",
    ")\n",
    "\n",
    "# Combine all POIs into a single GeoDataFrame\n",
    "poi_list = [gdf_shops, gdf_leisure, gdf_residential, gdf_amenities]\n",
    "gdf_pois = pd.concat(poi_list, ignore_index=True)\n",
    "print(f\"Combined {len(gdf_pois)} points of interest.\")\n",
    "\n",
    "# Re-project all data to a common Projected CRS for accurate distance calculation\n",
    "target_crs = \"EPSG:32148\"\n",
    "print(f\"Re-projecting all data to {target_crs} for accurate meter-based calculations\")\n",
    "gdf_afdc_unique = gdf_afdc_unique.to_crs(target_crs)\n",
    "gdf_roads = gdf_roads.to_crs(target_crs)\n",
    "gdf_pois = gdf_pois.to_crs(target_crs)\n",
    "print(\"Re-projection complete.\")\n",
    "\n",
    "\n",
    "# Calculate Distance to Nearest Major Road \n",
    "tqdm.pandas(desc=\"Calculating road distances\")\n",
    "# Filter for major road types\n",
    "major_road_types = ['motorway', 'trunk', 'primary', 'secondary']\n",
    "gdf_major_roads = gdf_roads[gdf_roads['highway'].isin(major_road_types)]\n",
    "\n",
    "# Calculate the minimum distance from each station to any major road\n",
    "print(f\"Calculating distance to nearest of {len(gdf_major_roads)} major road segments...\")\n",
    "gdf_afdc_unique['dist_to_major_road_m'] = gdf_afdc_unique.geometry.progress_apply(\n",
    "    lambda point: gdf_major_roads.distance(point).min()\n",
    ")\n",
    "print(\"Distance calculation complete.\")\n",
    "\n",
    "# --- 5. Calculate POI Density within 500m ---\n",
    "print(\"Calculating POI density within a 500-meter radius\")\n",
    "# Create a 500m buffer around each unique station\n",
    "buffers = gdf_afdc_unique.geometry.buffer(500)\n",
    "\n",
    "# Spatially join the POIs that are within each buffer\n",
    "joined_pois = gpd.sjoin(gdf_pois, gpd.GeoDataFrame(geometry=buffers), how=\"inner\", predicate=\"within\")\n",
    "\n",
    "# Group by the station index and count the number of POIs in each buffer\n",
    "poi_counts = joined_pois.groupby(joined_pois.index).size()\n",
    "\n",
    "# Add the counts back to the main DataFrame, filling stations with no nearby POIs with 0\n",
    "gdf_afdc_unique['poi_density_500m'] = poi_counts\n",
    "gdf_afdc_unique['poi_density_500m'] = gdf_afdc_unique['poi_density_500m'].fillna(0)\n",
    "print(\"POI density calculation complete.\")\n",
    "\n",
    "\n",
    "# --- 6. Display and Save Results ---\n",
    "print(\"\\\\n--- Feature Engineering Complete ---\")\n",
    "print(\"Sample of unique AFDC stations with new features:\")\n",
    "print(gdf_afdc_unique[['ID', 'Open Date', 'dist_to_major_road_m', 'poi_density_500m']].head())\n",
    "\n",
    "output_path = os.path.join(processed_path, \"afdc_unique_stations_with_features.geojson\")\n",
    "try:\n",
    "    gdf_afdc_unique.to_file(output_path, driver='GeoJSON')\n",
    "    print(f\"\\\\nSuccessfully saved updated GeoDataFrame to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\\\nError saving file: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd2aec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chargers from year 2025: 2979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/combined_afdc_data.csv\")\n",
    "\n",
    "#getting count of chargers from year 2025\n",
    "count_2025 = df[df['Year'] == 2025].shape[0]\n",
    "print(f\"Number of chargers from year 2025: {count_2025}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
